syntax = "proto3";

package epfl.distributed;

import "scalapb/scalapb.proto";
import "google/protobuf/empty.proto";

option (scalapb.options) = {
  import: "epfl.distributed.core.numberTypeMapper"
  import: "epfl.distributed.core.vecTypeMapper"
};

service Master {
    rpc RegisterSlave (Node) returns (Ack) {}
    rpc UnregisterSlave (Node) returns (Ack) {}

    // Async operation
    rpc UpdateGrad (GradUpdate) returns (Ack) {}
}

message Node {
    string host = 1;
    int32 port = 2;
}

message Ack {}

message Sparse {
    map<int32, double> map = 1 [(scalapb.field).value_type = "spire.math.Number"];
    int32 size = 2;
}

message GradUpdate {
    Sparse gradUpdate = 1 [(scalapb.field).type = "epfl.distributed.math.Vec", (scalapb.field).no_box = true];
}

service Slave {
    rpc RegisterSlave (Node) returns (Ack) {}
    rpc UnregisterSlave (Node) returns (Ack) {}

    // Sync operations
    rpc Forward (ForwardRequest) returns (ForwardReply) {}
    rpc Gradient (GradientRequest) returns (GradUpdate) {}

    // Async operations
    rpc StartAsync (StartAsyncRequest) returns (Ack) {}
    rpc StopAsync (google.protobuf.Empty) returns (Ack) {}
    rpc UpdateGrad (GradUpdate) returns (Ack) {}
}

message ForwardRequest {
    repeated int32 samples = 1 [packed=true];
    Sparse weights = 2 [(scalapb.field).type = "epfl.distributed.math.Vec", (scalapb.field).no_box = true];
}

message ForwardReply {
    repeated double predictions = 1 [(scalapb.field).type = "spire.math.Number"];
}

message GradientRequest {
    Sparse weights = 1 [(scalapb.field).type = "epfl.distributed.math.Vec", (scalapb.field).no_box = true];
    repeated int32 samples = 2 [packed=true];
}

message StartAsyncRequest {
    Sparse weights = 1 [(scalapb.field).type = "epfl.distributed.math.Vec", (scalapb.field).no_box = true];
    repeated int32 samples = 2;
    int32 batchSize = 3;
    double learningRate = 4;
}

